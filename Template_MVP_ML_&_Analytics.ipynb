{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6dab859",
   "metadata": {
    "id": "f6dab859"
   },
   "source": [
    "# Template — MVP: Machine Learning & Analytics\n",
    "**Autor:** Fábio Henrique Neves Reis Ribeiro\n",
    "\n",
    "**Data:** 28/09/2025\n",
    "\n",
    "**Matrícula:** 4052025000834\n",
    "\n",
    "**Tema:** Predição de renda anual > 50K USD a partir de dados censitários\n",
    "\n",
    "**Dataset:** UCI Adult Income (Census Income)\n",
    "\n",
    "> Este documento apresenta um estudo aplicado de aprendizado de máquina com foco em previsões de renda a partir de dados tabulares, enfatizando reprodutibilidade, rigor metodológico e discussão de viés/justiça algorítmica.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8c2e9",
   "metadata": {},
   "source": [
    "### Resumo\n",
    "Este trabalho investiga a capacidade de modelos de classificação em prever se indivíduos possuem renda anual superior a 50 mil dólares utilizando o conjunto de dados Adult (UCI). Implementamos um pipeline reprodutível de pré-processamento (imputação, padronização e codificação one-hot), com divisão estratificada em treino e teste. Foram avaliados modelos baseline e candidatos (Regressão Logística, Random Forest e Gradient Boosting), bem como otimização de hiperparâmetros via validação cruzada estratificada. As métricas consideradas incluem Acurácia, F1 ponderado, ROC AUC e AP. Também analisamos a calibração de probabilidades e aspectos de justiça algorítmica por sexo e raça. Os resultados indicam desempenho robusto (F1≈0,85 e ROC AUC≈0,91 para Gradient Boosting), com evidências de disparidades entre grupos demográficos, o que demanda cuidados adicionais de mitigação e governança.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670b1e8",
   "metadata": {
    "id": "a670b1e8"
   },
   "source": [
    "## 1. Escopo, objetivo e definição do problema\n",
    "Este estudo visa construir e avaliar modelos de classificação binária para prever se um indivíduo possui renda anual superior a 50 mil dólares, com base em atributos demográficos, educacionais e ocupacionais do dataset UCI Adult. O problema é representativo de cenários reais de análise socioeconômica e de risco de crédito.\n",
    "\n",
    "- Tipo de tarefa: classificação binária.\n",
    "- Domínio: dados tabulares (censitários).\n",
    "- Relevância: subsidia políticas públicas, estudos de desigualdade e decisões de crédito/marketing, exigindo atenção a vieses e justiça algorítmica.\n",
    "- Perguntas orientadoras: quais variáveis são mais preditivas? Quais modelos apresentam melhor compromisso entre desempenho e interpretabilidade? Há disparidades de desempenho entre grupos demográficos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0798fb",
   "metadata": {},
   "source": [
    "### 1.1 Premissas e hipóteses\n",
    "- Hipóteses: (i) idade, escolaridade, capital.gain e horas/semana aumentam a probabilidade de renda > 50K; (ii) existem disparidades entre grupos (sexo/raça) nas taxas positivas e erros.\n",
    "- Restrições/condições de seleção: uso do dataset Adult (UCI) completo; remoção de `fnlwgt` e de `education` textual (mantendo `education.num`); tratamento de `?` como ausente; divisão estratificada 80/20.\n",
    "- Ética e governança: atributos sensíveis são mantidos para auditoria de fairness e não para uso direto em decisão automatizada sem mitigação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd6e05",
   "metadata": {
    "id": "e1bd6e05"
   },
   "source": [
    "## 2. Reprodutibilidade e ambiente\n",
    "Utilizamos Python (3.13) com as bibliotecas numpy, pandas, scikit-learn, matplotlib e seaborn. As seeds são fixadas para reprodutibilidade. O workflow foi estruturado em pipelines para evitar vazamento e assegurar replicabilidade de transformações e predições."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5cec9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42b5cec9",
    "outputId": "eae2779c-167f-4b3f-b604-ec6417590e14"
   },
   "outputs": [],
   "source": [
    "# === Setup básico e reprodutibilidade ===\n",
    "import os, random, time, sys, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score, confusion_matrix,\n",
    "                             mean_absolute_error, mean_squared_error, r2_score,\n",
    "                             silhouette_score)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Para frameworks que suportam seed adicional (ex.: PyTorch/TensorFlow), documente aqui:\n",
    "# import torch; torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
    "# import tensorflow as tf; tf.random.set_seed(SEED)\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Seed global:\", SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5e5595",
   "metadata": {
    "id": "ad5e5595"
   },
   "source": [
    "\n",
    "### 2.1 Dependências (opcional)\n",
    "Instale pacotes extras se necessário. **Mantenha o projeto enxuto** para facilitar a correção.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dcc62e",
   "metadata": {
    "id": "05dcc62e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Exemplo: descomente o que precisar\n",
    "# !pip install -q scikit-learn imbalanced-learn xgboost lightgbm catboost optuna\n",
    "# !pip install -q pandas-profiling ydata-profiling\n",
    "# !pip install -q matplotlib seaborn plotly\n",
    "# !pip install -q statsmodels pmdarima\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yTTTI_gjtEbp",
   "metadata": {
    "id": "yTTTI_gjtEbp"
   },
   "source": [
    "### 2.2 Funções python (opcional)\n",
    "Defina, se necessário, funções em Python para reutilizar seu código e torná-lo mais organizado. Essa é uma boa prática de programação que facilita a leitura, manutenção e evolução do seu projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6PQYS9MftOLB",
   "metadata": {
    "id": "6PQYS9MftOLB"
   },
   "outputs": [],
   "source": [
    "def evaluate_classification(y_true, y_pred, proba=None):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1w = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    auc = roc_auc_score(y_true, proba[:,1]) if (proba is not None and proba.shape[1]==2) else np.nan\n",
    "    return {\"accuracy\": acc, \"f1_weighted\": f1w, \"roc_auc\": auc}\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"MAE\": mae, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "def evaluate_clustering(X_original, model):\n",
    "    # Silhouette requer >1 cluster e dados transformados\n",
    "    try:\n",
    "        if hasattr(model.named_steps[\"pre\"], \"transform\"):\n",
    "            X_emb = model.named_steps[\"pre\"].fit_transform(X_original)  # cuidado: apenas para demo\n",
    "        else:\n",
    "            X_emb = X_original\n",
    "        labels = model.named_steps[\"model\"].fit_predict(X_emb)\n",
    "        sil = silhouette_score(X_emb, labels)\n",
    "        return {\"silhouette\": sil}\n",
    "    except Exception as e:\n",
    "        return {\"silhouette\": np.nan, \"erro\": str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d8aa8",
   "metadata": {
    "id": "ad1d8aa8"
   },
   "source": [
    "## 3. Dados: fonte, entendimento e qualidade\n",
    "O conjunto Adult (UCI) reúne atributos demográficos e laborais de indivíduos, incluindo idade, escolaridade, estado civil, ocupação, horas trabalhadas, origem e sexo, com a variável alvo indicando renda anual acima/abaixo de 50K USD. Tratamos entradas ausentes e valores “?” em colunas categóricas, e removemos redundâncias (ex.: mantida education.num e removida education textual). A variável de peso (fnlwgt) foi descartada por não contribuir diretamente à predição neste escopo. O alvo binário foi derivado de income. Preservamos colunas sensíveis (sexo, raça) para análise de fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c90f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "e03c90f7",
    "outputId": "915c64fb-d263-489f-a10e-90c4e5b1d13d"
   },
   "outputs": [],
   "source": [
    "# === Carga dos dados ===\n",
    "# Dataset: Adult Income (UCI). Arquivo no workspace: adult.csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar CSV a partir da URL (raw do GitHub)\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/fhnribeiro/mvp-puc-machine-learning/main/data/adult.csv\")\n",
    "\n",
    "# Normalizações iniciais\n",
    "# - Espaços/\"?\" como desconhecido nas colunas categóricas\n",
    "cat_cols_guess = df.select_dtypes(include=['object']).columns.tolist()\n",
    "for c in cat_cols_guess:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "    df[c] = df[c].replace({'?': np.nan})\n",
    "\n",
    "# Converter target para binário (<=50K -> 0, >50K -> 1)\n",
    "if 'income' in df.columns:\n",
    "    df['income_binary'] = (df['income'] == '>50K').astype(int)\n",
    "\n",
    "# Remover colunas de IDs/pesos que tendem a poluir (fnlwgt é controversa)\n",
    "drop_candidates = []\n",
    "if 'fnlwgt' in df.columns:\n",
    "    drop_candidates.append('fnlwgt')\n",
    "\n",
    "# education.num é redundante com education; manteremos education.num e removeremos education (ou vice-versa). Aqui, manteremos education.num.\n",
    "if 'education' in df.columns:\n",
    "    drop_candidates.append('education')\n",
    "\n",
    "# Não removeremos 'native.country' por ora; poderemos agrupar países raros depois.\n",
    "\n",
    "cols_to_use = [c for c in df.columns if c not in drop_candidates]\n",
    "df = df[cols_to_use]\n",
    "\n",
    "display(df.sample(5))\n",
    "print('\\nFormato:', df.shape)\n",
    "print('\\nTipos:')\n",
    "print(df.dtypes)\n",
    "print('\\nValores ausentes por coluna:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0bb41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "id": "c2a0bb41",
    "outputId": "55a10a1c-81b9-4a5c-d2c5-50e24e9482b9"
   },
   "outputs": [],
   "source": [
    "# Verificações adicionais específicas do Adult\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Distribuição do target\n",
    "if 'income_binary' in df.columns:\n",
    "    ax = df['income_binary'].value_counts(normalize=True).mul(100).rename({0:'<=50K',1:'>50K'}).plot(kind='bar', rot=0)\n",
    "    plt.title('Distribuição do target (%)')\n",
    "    plt.ylabel('%')\n",
    "    plt.show()\n",
    "\n",
    "# Estatísticas numéricas\n",
    "print('\\nEstatísticas descritivas (numéricas):')\n",
    "display(df.select_dtypes(include=[np.number]).describe().T)\n",
    "\n",
    "# Principais categorias por coluna categórica\n",
    "for c in df.select_dtypes(include=['object']).columns:\n",
    "    vc = df[c].value_counts(dropna=False).head(10)\n",
    "    print(f\"\\nTop categorias - {c}:\")\n",
    "    print(vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4922028c",
   "metadata": {
    "id": "4922028c"
   },
   "source": [
    "### 3.1 Análise exploratória resumida (EDA)\n",
    "A distribuição do alvo é desbalanceada (classe <=50K majoritária). Variáveis como idade, educação (numérica), capital.gain e hours.per.week apresentam associações relevantes com o alvo. Em categorias, observou-se heterogeneidade entre grupos (p.ex., sexo e raça), reforçando a necessidade de avaliação de impacto algorítmico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93654e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 903
    },
    "id": "b93654e5",
    "outputId": "27e724fe-e2c8-43d6-e970-d01b0e2662bd"
   },
   "outputs": [],
   "source": [
    "# EDA essencial\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.drop(['income_binary'], errors='ignore')\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Histogramas numéricos\n",
    "_ = df[num_cols].hist(figsize=(12,8), bins=30)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Relação simples de algumas numéricas com target\n",
    "if 'income_binary' in df.columns:\n",
    "    sns.boxplot(data=df, x='income_binary', y='age')\n",
    "    plt.title('Age vs income_binary'); plt.show()\n",
    "    sns.boxplot(data=df, x='income_binary', y='hours.per.week')\n",
    "    plt.title('Hours per week vs income_binary'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d88464",
   "metadata": {
    "id": "92d88464"
   },
   "source": [
    "## 4. Target, variáveis e divisão\n",
    "O alvo adotado foi income_binary (1 se >50K). Evitamos vazamento excluindo a coluna textual income das features. A divisão treino/teste foi estratificada (80/20). A tipagem reflete dados mistos (numéricos e categóricos), tratados via pipeline de pré-processamento para garantir consistência entre treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256d179",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5256d179",
    "outputId": "b074e092-e165-4b15-e220-d4572a289c82"
   },
   "outputs": [],
   "source": [
    "# Seleção do problema e split\n",
    "PROBLEM_TYPE = 'classificacao'\n",
    "\n",
    "# Target e features\n",
    "target = 'income_binary'\n",
    "# Remover também colunas derivadas/relacionadas ao target para evitar vazamento (ex.: 'income')\n",
    "leak_cols = ['income'] if 'income' in df.columns else []\n",
    "features = [c for c in df.columns if c not in [target] + leak_cols]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df[features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# Tipos\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED, stratify=y\n",
    ")\n",
    "\n",
    "print('Treino:', X_train.shape, '| Teste:', X_test.shape)\n",
    "print('num_cols:', num_cols)\n",
    "print('cat_cols:', cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6a61e2",
   "metadata": {
    "id": "2a6a61e2"
   },
   "source": [
    "## 5. Pré-processamento (Pipeline)\n",
    "O pipeline aplica imputação (mediana para numéricas e moda para categóricas), padronização (numéricas) e codificação one-hot (categóricas). Essa abordagem encapsula transformações e previne vazamento, além de facilitar tuning e implantação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f54b2a7",
   "metadata": {},
   "source": [
    "### 5.1 Visões/preprocessamento alternativos\n",
    "Para comparação, podemos testar uma visão com transformação log1p em `capital.gain`/`capital.loss` e padronização robusta (RobustScaler), mantendo o mesmo split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6257ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c6257ce",
    "outputId": "75f28ced-9cda-48b7-d76a-8e334c14b515"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))  # usar dense por padrão\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_pipe, num_cols),\n",
    "    (\"cat\", categorical_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline alternativo: log1p em ganhos/perdas + RobustScaler\n",
    "from sklearn.preprocessing import FunctionTransformer, RobustScaler\n",
    "\n",
    "def add_log1p_cols(df_in):\n",
    "    X = df_in.copy()\n",
    "    for c in ['capital.gain', 'capital.loss']:\n",
    "        if c in X.columns:\n",
    "            X[c] = np.log1p(X[c].astype(float))\n",
    "    return X\n",
    "\n",
    "log_transformer = FunctionTransformer(add_log1p_cols, validate=False, feature_names_out='one-to-one')\n",
    "\n",
    "numeric_pipe_alt = Pipeline(steps=[\n",
    "    (\"log1p\", FunctionTransformer(lambda X: np.log1p(X), validate=False)),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", RobustScaler())\n",
    "])\n",
    "\n",
    "# Observação: como a transformação log1p foi feita em todo numeric pipe, é alternativa simples; para granularidade por coluna use ColumnTransformer adicional.\n",
    "preprocess_alt = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_pipe_alt, num_cols),\n",
    "    (\"cat\", categorical_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "preprocess_alt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a161e54",
   "metadata": {
    "id": "2a161e54"
   },
   "source": [
    "## 6. Modelagem\n",
    "Iniciamos com baseline (classe majoritária) e comparamos modelos clássicos para dados tabulares: Regressão Logística e Random Forest. Em seguida, avaliamos variantes com balanceamento de classes e Gradient Boosting. O tuning de hiperparâmetros foi conduzido com validação cruzada estratificada (5 folds)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c618f",
   "metadata": {},
   "source": [
    "### 6.3 Seleção de atributos (feature selection)\n",
    "Avaliamos seleção baseada em coeficientes (LogReg L1) e em importância de árvore (RF), comparando desempenho com o conjunto completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4aabf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "d2a4aabf",
    "outputId": "d4bbe5c0-363a-4672-dff6-4422d99896f8"
   },
   "outputs": [],
   "source": [
    "# Baseline e modelos\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "baseline = Pipeline([\n",
    "    (\"pre\", preprocess),\n",
    "    (\"model\", DummyClassifier(strategy=\"most_frequent\", random_state=SEED))\n",
    "])\n",
    "\n",
    "candidates = {\n",
    "    \"LogisticRegression\": Pipeline([\n",
    "        (\"pre\", preprocess),\n",
    "        (\"model\", LogisticRegression(max_iter=1000, n_jobs=None, solver='lbfgs'))\n",
    "    ]),\n",
    "    \"RandomForest\": Pipeline([\n",
    "        (\"pre\", preprocess),\n",
    "        (\"model\", RandomForestClassifier(random_state=SEED))\n",
    "    ])\n",
    "}\n",
    "\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aae534",
   "metadata": {
    "id": "75aae534"
   },
   "source": [
    "\n",
    "### 6.1 Treino e avaliação rápida (baseline vs candidatos)\n",
    "Use **métricas adequadas** ao tipo de problema. Documente suas observações.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c005dba",
   "metadata": {},
   "source": [
    "### 6.2 Modelos adicionais e class weights\n",
    "Vamos testar variantes com balanceamento de classes e um modelo de Gradient Boosting, comparando as métricas no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d4daa2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "d9d4daa2",
    "outputId": "13903732-df32-4fcc-f9cb-530a049b671f"
   },
   "outputs": [],
   "source": [
    "# Treino rápido e avaliação\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Baseline\n",
    "baseline.fit(X_train, y_train)\n",
    "y_pred = baseline.predict(X_test)\n",
    "proba = baseline.predict_proba(X_test)[:,1] if hasattr(baseline, 'predict_proba') else None\n",
    "results['baseline'] = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'f1_weighted': f1_score(y_test, y_pred, average='weighted'),\n",
    "    'roc_auc': roc_auc_score(y_test, proba) if proba is not None else np.nan,\n",
    "}\n",
    "\n",
    "# Candidatos\n",
    "for name, pipe in candidates.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    proba = pipe.predict_proba(X_test)[:,1] if hasattr(pipe, 'predict_proba') else None\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1_weighted': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'roc_auc': roc_auc_score(y_test, proba) if proba is not None else np.nan,\n",
    "    }\n",
    "\n",
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7939c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação de modelos adicionais\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "extra_models = {\n",
    "    'LogReg_balanced': Pipeline([\n",
    "        ('pre', preprocess),\n",
    "        ('model', LogisticRegression(max_iter=1000, class_weight='balanced', solver='lbfgs'))\n",
    "    ]),\n",
    "    'RF_balanced': Pipeline([\n",
    "        ('pre', preprocess),\n",
    "        ('model', RandomForestClassifier(random_state=SEED, class_weight='balanced'))\n",
    "    ]),\n",
    "    'GradientBoosting': Pipeline([\n",
    "        ('pre', preprocess),\n",
    "        ('model', GradientBoostingClassifier(random_state=SEED))\n",
    "    ])\n",
    "}\n",
    "\n",
    "for name, pipe in extra_models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    proba = pipe.predict_proba(X_test)[:,1] if hasattr(pipe, 'predict_proba') else None\n",
    "    results[name] = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1_weighted': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'roc_auc': roc_auc_score(y_test, proba) if proba is not None else np.nan,\n",
    "    }\n",
    "\n",
    "pd.DataFrame(results).T.sort_values('f1_weighted', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2706ef09",
   "metadata": {
    "id": "2706ef09"
   },
   "source": [
    "## 7. Validação e otimização\n",
    "Utilizamos RandomizedSearchCV com 5-fold estratificado para Random Forest, otimizando número de estimadores, profundidade e critérios de divisão/folhas. Métrica de seleção: F1 ponderado. Este procedimento atenua variância e melhora o compromisso viés-variância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3ea5c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8db3ea5c",
    "outputId": "7ca7ba9d-8b11-468a-fe1e-e1bc03cd182d"
   },
   "outputs": [],
   "source": [
    "# Validação e tuning (RandomForest como exemplo)\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "model = Pipeline([\n",
    "    (\"pre\", preprocess),\n",
    "    (\"model\", RandomForestClassifier(random_state=SEED))\n",
    "])\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": randint(200, 600),\n",
    "    \"model__max_depth\": randint(4, 30),\n",
    "    \"model__min_samples_split\": randint(2, 15),\n",
    "    \"model__min_samples_leaf\": randint(1, 10)\n",
    "}\n",
    "search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=15, cv=cv, scoring='f1_weighted', random_state=SEED, n_jobs=-1, verbose=1)\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Melhor score (CV):\", search.best_score_)\n",
    "print(\"Melhores parâmetros:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2813cb34",
   "metadata": {
    "id": "2813cb34"
   },
   "source": [
    "## 8. Avaliação final, análise de erros e limitações\n",
    "Comparamos desempenho no teste (accuracy, F1 ponderado, ROC AUC, AP), apresentamos matriz de confusão e curvas ROC/PR. Complementamos com calibração de probabilidades (Brier, curvas de calibração) e análise de fairness por sexo/raça. Limitações incluem desbalanceamento, possíveis vieses estruturais e representatividade amostral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef9d7d",
   "metadata": {},
   "source": [
    "### 8.3 Fairness por grupo (sexo e raça)\n",
    "Métricas por grupo: suporte, taxa positiva, TPR (recall positivo), FPR e disparate impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7a17d",
   "metadata": {},
   "source": [
    "### 8.2 Calibração de probabilidades\n",
    "Comparar modelo calibrado vs não calibrado (Brier, ROC AUC, AP) e curva de calibração."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ccb42d",
   "metadata": {},
   "source": [
    "### 8.1 Curvas ROC e Precision-Recall\n",
    "Curvas para o melhor modelo (do tuning) no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e851c60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "4e851c60",
    "outputId": "4749ba46-b891-4861-8803-a2485a31ea24"
   },
   "outputs": [],
   "source": [
    "# Avaliação final no teste\n",
    "y_pred = search.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['<=50K','>50K']))\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_estimator(search.best_estimator_, X_test, y_test)\n",
    "plt.title('Matriz de Confusão - Melhor Modelo')\n",
    "plt.show()\n",
    "\n",
    "# Importância de atributos (RandomForest)\n",
    "best_rf = search.best_estimator_.named_steps['model']\n",
    "# Para mapear os nomes das colunas após OneHot, precisamos acessar o preprocess\n",
    "ohe = search.best_estimator_.named_steps['pre'].named_transformers_['cat'].named_steps['onehot']\n",
    "num_names = num_cols\n",
    "cat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "feature_names = list(num_names) + cat_names\n",
    "importances = best_rf.feature_importances_\n",
    "idx = np.argsort(importances)[-20:]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh([feature_names[i] for i in idx], importances[idx])\n",
    "plt.title('Top 20 Importâncias (RandomForest)')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0365e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fairness: métricas por grupo\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predições do melhor modelo\n",
    "y_hat = best_est.predict(X_test)\n",
    "\n",
    "def group_metrics(df_test, y_true, y_pred, group_col):\n",
    "    out = []\n",
    "    groups = df_test[group_col].fillna('NA').astype(str).values\n",
    "    for g in pd.Series(groups).unique():\n",
    "        mask = (groups == g)\n",
    "        yt = y_true[mask]\n",
    "        yp = y_pred[mask]\n",
    "        if yt.shape[0] == 0:\n",
    "            continue\n",
    "        tn, fp, fn, tp = confusion_matrix(yt, yp, labels=[0,1]).ravel()\n",
    "        support = yt.shape[0]\n",
    "        positive_rate = (yp==1).mean()\n",
    "        tpr = tp / (tp + fn) if (tp+fn)>0 else np.nan\n",
    "        fpr = fp / (fp + tn) if (fp+tn)>0 else np.nan\n",
    "        out.append({\n",
    "            group_col: g,\n",
    "            'support': int(support),\n",
    "            'positive_rate': positive_rate,\n",
    "            'TPR': tpr,\n",
    "            'FPR': fpr,\n",
    "        })\n",
    "    res = pd.DataFrame(out)\n",
    "    if not res.empty:\n",
    "        # Disparate impact: razão da taxa positiva vs grupo com maior taxa\n",
    "        max_rate = res['positive_rate'].max()\n",
    "        res['disparate_impact'] = res['positive_rate'] / max_rate\n",
    "    return res.sort_values('support', ascending=False)\n",
    "\n",
    "print('Por sexo:')\n",
    "display(group_metrics(X_test, y_test.values, y_hat, 'sex'))\n",
    "print('\\nPor raça:')\n",
    "display(group_metrics(X_test, y_test.values, y_hat, 'race'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a6417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibração (Platt ou isotônica)\n",
    "from sklearn.calibration import CalibratedClassifierCV, CalibrationDisplay\n",
    "\n",
    "# Usa melhor modelo do search como base (RandomForest)\n",
    "base_model = search.best_estimator_\n",
    "calibrated = CalibratedClassifierCV(base_model, method='isotonic', cv=3)\n",
    "calibrated.fit(X_train, y_train)\n",
    "proba_cal = calibrated.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('ROC AUC (base):', roc_auc_score(y_test, proba))\n",
    "print('ROC AUC (calibrado):', roc_auc_score(y_test, proba_cal))\n",
    "print('AP (base):', average_precision_score(y_test, proba))\n",
    "print('AP (calibrado):', average_precision_score(y_test, proba_cal))\n",
    "print('Brier (base):', brier_score_loss(y_test, proba))\n",
    "print('Brier (calibrado):', brier_score_loss(y_test, proba_cal))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,5))\n",
    "CalibrationDisplay.from_predictions(y_test, proba, n_bins=10, name='Base', ax=ax)\n",
    "CalibrationDisplay.from_predictions(y_test, proba_cal, n_bins=10, name='Calibrado', ax=ax)\n",
    "plt.title('Curva de Calibração'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas ROC/PR para o melhor modelo (search.best_estimator_)\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay, average_precision_score, brier_score_loss\n",
    "\n",
    "best_est = search.best_estimator_\n",
    "proba = best_est.predict_proba(X_test)[:,1]\n",
    "RocCurveDisplay.from_predictions(y_test, proba)\n",
    "plt.title('ROC Curve - Melhor Modelo'); plt.show()\n",
    "PrecisionRecallDisplay.from_predictions(y_test, proba)\n",
    "ap = average_precision_score(y_test, proba)\n",
    "plt.title(f'Precision-Recall - Melhor Modelo (AP={ap:.3f})'); plt.show()\n",
    "print('Brier score (quanto menor melhor):', brier_score_loss(y_test, proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0103a7f9",
   "metadata": {
    "id": "0103a7f9"
   },
   "source": [
    "## 12. Conclusões e próximos passos\n",
    "Este estudo demonstrou a viabilidade de prever renda anual > 50K USD a partir de variáveis demográficas e ocupacionais do dataset Adult (UCI), utilizando um pipeline reprodutível de pré-processamento e modelos clássicos para dados tabulares. Os resultados foram consistentes e alinhados com a literatura para esse conjunto de dados, com desempenho competitivo e interpretável.\n",
    "\n",
    "Principais achados\n",
    "- Desempenho de modelos: o baseline (classe majoritária) foi superado por Regressão Logística, Random Forest e, sobretudo, Gradient Boosting. Nesta execução, o Gradient Boosting exibiu desempenho robusto (aprox. F1≈0,85; ROC AUC≈0,91), com a Regressão Logística próxima (F1≈0,85; ROC AUC≈0,90) e Random Forest levemente abaixo. O tuning via validação cruzada estratificada melhorou a robustez do Random Forest sem alterar substancialmente a hierarquia entre modelos.\n",
    "- Variáveis relevantes: idade, escolaridade (education.num), capital.gain e hours.per.week emergiram como preditores com maior contribuição, conforme importâncias (RF) e relações exploratórias. Em geral, maior escolaridade, maior capital.gain e mais horas semanais correlacionaram-se positivamente com probabilidade de renda > 50K.\n",
    "- Calibração de probabilidades: a calibração (isotônica) melhorou a qualidade probabilística (menor Brier e curva de calibração mais próxima da diagonal), relevante para cenários com custos assimétricos ou decisões baseadas em limiares (ex.: elegibilidade a programas/benefícios). Mesmo quando a AUC/AP mudam pouco, a calibração auxilia na decisão operacional (thresholding) e em comparabilidade entre períodos.\n",
    "- Fairness e disparidades: observamos assimetrias por sexo e raça. Exemplificativamente, a taxa positiva prevista foi maior para o grupo masculino do que para o feminino, com disparate impact < 1 para mulheres; por raça, o grupo “White” tendeu a apresentar taxa positiva superior à de “Black” e outros, novamente com disparate impact < 1. Além das taxas, diferenças em TPR/FPR entre grupos indicam potenciais vieses operacionais (falsos positivos/negativos desbalanceados). Esses achados demandam mitigação e governança antes de qualquer uso sensível.\n",
    "\n",
    "Interpretação e implicações\n",
    "- Viabilidade: os resultados indicam que modelos clássicos conseguem capturar boa parte da variação relevante no alvo, com custo computacional moderado e interpretabilidade razoável (coeficientes na Regressão Logística, importâncias no RF/GB).\n",
    "- Trade-offs: há um equilíbrio entre desempenho, interpretabilidade e justiça. Gradient Boosting pode oferecer ganhos marginais de F1/AUC, enquanto a Regressão Logística facilita explicações e auditorias. A escolha depende do contexto regulatório, impacto do erro e necessidade de transparência.\n",
    "- Riscos: atributos sensíveis (sexo, raça) e correlatos podem induzir disparidades. Mesmo com boa métrica global, gaps entre grupos podem inviabilizar certos usos ou requerer controles adicionais (documentação de riscos, testes de equidade, revisão humana).\n",
    "\n",
    "Limitações\n",
    "- Dados e representatividade: base estática, com possíveis vieses de cobertura e coleta; não garante generalização para outras populações/épocas sem revalidação.\n",
    "- Escopo de features: não realizamos engenharia exaustiva (interações, binning por faixas etárias, efeitos não lineares específicos), nem removemos/mascaramos totalmente variáveis sensíveis.\n",
    "- Custo e limiares: não otimizamos explicitamente custos assimétricos (FN vs FP) por caso de uso; thresholds foram comparados de forma genérica.\n",
    "- Avaliação temporal: não avaliamos estabilidade temporal (drift) ou performance sob mudança de distribuição.\n",
    "\n",
    "Próximos passos recomendados\n",
    "- Modelagem: avaliar famílias de boosting mais modernas (XGBoost/LightGBM/CatBoost) com tuning sistemático e, se aplicável, calibrar probabilidades (CalibratedClassifierCV) e comparar Brier/AP/AUC.\n",
    "- Engenharia de atributos: explorar interações (idade×horas, educação×ocupação), faixas etárias (binning), e tratamento de países raros (agrupamentos). Testar seleção de variáveis e regularização (L1/L2) para parcimônia.\n",
    "- Fairness: aplicar técnicas de mitigação (reponderação, ajustes de limiar por grupo, restrição de sensíveis/dummies proxy), definir métricas-alvo (ex.: equalized odds, demographic parity) e estabelecer tolerâncias e auditorias periódicas.\n",
    "- Operacionalização: criar Model Card/Data Sheet, registrar experimentos e métricas, automatizar monitoramento (distribuições, performance e fairness), política de retreinamento e testes de regressão de modelo.\n",
    "- Governança: definir critérios de uso aceito, validação por especialistas e fallback humano para casos limítrofes; documentar riscos éticos e impactos.\n",
    "\n",
    "Conclusão\n",
    "Em síntese, o pipeline proposto é tecnicamente sólido e reprodutível, alcançando desempenho competitivo em Adult Income. Para adoção responsável, recomenda-se avançar em calibração, mitigação de vieses e governança do ciclo de vida do modelo, alinhando desempenho com requisitos éticos, regulatórios e de negócio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a7b78e",
   "metadata": {
    "id": "b3a7b78e"
   },
   "source": [
    "## 10. Salvando artefatos (modelos e pipeline)\n",
    "Registramos os artefatos do melhor modelo e do calibrado, além de um arquivo de métricas em JSON para rastreabilidade e comparação entre execuções."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf45e1d",
   "metadata": {},
   "source": [
    "### 10.1 Salvando artefatos e métricas\n",
    "Vamos salvar o melhor pipeline e, se treinado, o calibrado; além de registrar métricas em JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jtoOdQDqzCiB",
   "metadata": {
    "id": "jtoOdQDqzCiB"
   },
   "outputs": [],
   "source": [
    "# Salvar artefatos\n",
    "import json, os\n",
    "from joblib import dump\n",
    "\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "\n",
    "# Salvar melhor pipeline\n",
    "best_path = os.path.join('artifacts', 'best_pipeline.joblib')\n",
    "dump(search.best_estimator_, best_path)\n",
    "print('Pipeline salvo em:', best_path)\n",
    "\n",
    "# Se existir modelo calibrado, salvar também\n",
    "try:\n",
    "    cal_path = os.path.join('artifacts', 'calibrated_pipeline.joblib')\n",
    "    dump(calibrated, cal_path)\n",
    "    print('Pipeline calibrado salvo em:', cal_path)\n",
    "except NameError:\n",
    "    print('Modelo calibrado não treinado nesta execução.')\n",
    "\n",
    "# Salvar métricas principais do melhor modelo no teste\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, average_precision_score, brier_score_loss\n",
    "proba = search.best_estimator_.predict_proba(X_test)[:,1]\n",
    "y_pred = search.best_estimator_.predict(X_test)\n",
    "metrics = {\n",
    "    'accuracy': float(accuracy_score(y_test, y_pred)),\n",
    "    'f1_weighted': float(f1_score(y_test, y_pred, average='weighted')),\n",
    "    'roc_auc': float(roc_auc_score(y_test, proba)),\n",
    "    'average_precision': float(average_precision_score(y_test, proba)),\n",
    "    'brier': float(brier_score_loss(y_test, proba))\n",
    "}\n",
    "with open(os.path.join('artifacts', 'metrics.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "print('Métricas salvas em artifacts/metrics.json')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
